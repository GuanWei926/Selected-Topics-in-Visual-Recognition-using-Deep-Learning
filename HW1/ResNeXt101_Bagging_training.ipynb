{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from PIL import Image\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract the compressed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the .tar.gz file\n",
    "with tarfile.open('hw1-data.tar.gz', 'r:gz') as archive:\n",
    "    archive.extractall()  # The folder where the contents will be extracted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformations for the images (resize, normalize, etc.)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.autoaugment.AutoAugment(),  # AutoAugment\n",
    "    transforms.RandomResizedCrop(224),  # Crop to 224x224\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
    "    transforms.ToTensor(),          # Convert images to tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])  # Normalize images\n",
    "])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    # transforms.Resize((224, 224)),  # Resize all images to 224x224\n",
    "    transforms.Resize(256),  # Resize all images to 256x256\n",
    "    transforms.CenterCrop(224),  # Crop to 224x224\n",
    "    transforms.ToTensor(),          # Convert images to tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])  # Normalize images\n",
    "])\n",
    "\n",
    "# Define the path to the extracted data folder\n",
    "data_dir = 'data'\n",
    "\n",
    "# Load datasets from the respective directories (train, valid, test)\n",
    "train_dataset = datasets.ImageFolder(os.path.join(data_dir, 'train'),\n",
    "                                     transform=train_transform)\n",
    "valid_dataset = datasets.ImageFolder(os.path.join(data_dir, 'val'),\n",
    "                                     transform=transform)\n",
    "\n",
    "# Create DataLoader objects for batching and shuffling the data\n",
    "train_loader = DataLoader(train_dataset, batch_size=32,\n",
    "                          shuffle=True, num_workers=4)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32,\n",
    "                          shuffle=False, num_workers=4)\n",
    "\n",
    "for images, labels in train_loader:\n",
    "    print(labels)\n",
    "    print(images.shape, labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create Bootstrapped Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bootstrap_loader(dataset, batch_size, n_samples):\n",
    "    indices = np.random.choice(len(dataset), n_samples, replace=True)\n",
    "    subset = Subset(dataset, indices)\n",
    "    loader = DataLoader(subset, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=4)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pretrained ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    model = models.resnext101_64x4d(pretrained=True)\n",
    "\n",
    "    # Freeze the first two layers\n",
    "    for name, param in model.named_parameters():\n",
    "        if name.startswith(\"layer1\"):\n",
    "            param.requires_grad = False\n",
    "\n",
    "    # Modify the fully connected layer for new number of classes\n",
    "    num_ftrs = model.fc.in_features\n",
    "    num_classes = 100\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    '''\n",
    "    print(torch.cuda.is_available())\n",
    "    print(torch.version.cuda)\n",
    "    print(torch.backends.cudnn.enabled)\n",
    "    '''\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    # calculate the number of parameters in the model\n",
    "    total_params = sum(p.numel()\n",
    "                       for p in model.parameters())\n",
    "    trainable_params = sum(p.numel()\n",
    "                           for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total parameters: {total_params}\")\n",
    "    print(f\"Trainable parameters: {trainable_params}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_models = []\n",
    "\n",
    "\n",
    "def train(num_models=8, epochs=10):\n",
    "    for i in range(num_models):\n",
    "        model = get_model()\n",
    "        best_model = model\n",
    "        best_model_loss = 0\n",
    "        best_acc = 0\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.00008)\n",
    "        print(f\"\\nTraining model {i+1}/{num_models}\")\n",
    "\n",
    "        loader = create_bootstrap_loader(train_dataset, batch_size=32,\n",
    "                                         n_samples=len(train_dataset))\n",
    "        # loader = train_loader\n",
    "        for epoch in range(epochs):\n",
    "            # training phase\n",
    "            model.train()\n",
    "            for images, labels in loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(images)\n",
    "                loss = criterion(output, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            # print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "            # scheduler.step()\n",
    "\n",
    "            # validation phase\n",
    "            model.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for images, labels in valid_loader:\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    output = model(images)\n",
    "                    _, predicted = torch.max(output, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "\n",
    "            acc = correct / total\n",
    "            # print(f\"Epoch {epoch + 1}, Accuracy: {acc}\")\n",
    "\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_model = copy.deepcopy(model)\n",
    "                best_model_loss = loss.item()\n",
    "                print(f\"Epoch {epoch + 1}, Accuracy: {acc}\")\n",
    "                print(f\"Best model so far with accuracy: {best_acc}\")\n",
    "            elif acc == best_acc and loss.item() < best_model_loss:\n",
    "                best_model = copy.deepcopy(model)\n",
    "                best_model_loss = loss.item()\n",
    "                print(f\"Epoch {epoch + 1}, Accuracy: {acc}\")\n",
    "                print(f\"Best model so far with accuracy: {best_acc}\\n\")\n",
    "\n",
    "            '''\n",
    "            if (epoch+1) % 5 == 0:\n",
    "                print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
    "                print(f\"Epoch {epoch + 1}, Accuracy: {acc}\")'\n",
    "            '''\n",
    "\n",
    "        torch.save(best_model.state_dict(),\n",
    "                   f'./checkpoint/ResNeXt101_64x4d_Bagging{i+1}.pth')\n",
    "        bagging_models.append(best_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(num_models=9, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, test_dir, transform=None):\n",
    "        self.test_dir = test_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = sorted([f for f in os.listdir(test_dir)\n",
    "                                   if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.test_dir, img_name)\n",
    "\n",
    "        file_name = os.path.splitext(img_name)[0]\n",
    "\n",
    "        # Load image\n",
    "        image = Image.open(img_path)\n",
    "\n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TestDataset(\"./data/test\", transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32,\n",
    "                         shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) testing after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "all_predictions = []\n",
    "for model in bagging_models:\n",
    "    model.to(device)\n",
    "    class_name = train_dataset.classes\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    filenames = []\n",
    "    with torch.no_grad():\n",
    "        for images, file_names in tqdm(test_loader):\n",
    "            images = images.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Get predicted class\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # Map predicted indices to class names\n",
    "            predicted_labels = [class_name[p]\n",
    "                                for p in preds.cpu().numpy()]\n",
    "\n",
    "            # Append to predictions\n",
    "            predictions.extend(predicted_labels)\n",
    "            filenames.extend(file_names)\n",
    "    all_predictions.append(predictions)\n",
    "\n",
    "\n",
    "# majority voting\n",
    "predictions = []\n",
    "for i in range(len(all_predictions[0])):\n",
    "    pred = []\n",
    "    for j in range(len(all_predictions)):\n",
    "        pred.append(all_predictions[j][i])\n",
    "    predictions.append(max(set(pred), key=pred.count))\n",
    "\n",
    "# Create DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'image_name': filenames,\n",
    "    'pred_label': predictions\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "output_csv = 'prediction.csv'\n",
    "results_df.to_csv(output_csv, index=False)\n",
    "print(f\"Predictions saved to {output_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) testing directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "all_predictions = []\n",
    "for i in range(9):\n",
    "    model = models.resnext101_64x4d(pretrained=True)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    num_classes = 100\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    model = model.to(device)\n",
    "    model_path = f'./checkpoint/ResNeXt101_64x4d_Bagging{i+1}.pth'\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    class_name = train_dataset.classes\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    filenames = []\n",
    "    with torch.no_grad():\n",
    "        for images, file_names in tqdm(test_loader):\n",
    "            images = images.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Get predicted class\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # Map predicted indices to class names\n",
    "            predicted_labels = [class_name[p]\n",
    "                                for p in preds.cpu().numpy()]\n",
    "\n",
    "            # Append to predictions\n",
    "            predictions.extend(predicted_labels)\n",
    "            filenames.extend(file_names)\n",
    "    all_predictions.append(predictions)\n",
    "\n",
    "\n",
    "# majority voting\n",
    "predictions = []\n",
    "for i in range(len(all_predictions[0])):\n",
    "    pred = []\n",
    "    for j in range(len(all_predictions)):\n",
    "        pred.append(all_predictions[j][i])\n",
    "    predictions.append(max(set(pred), key=pred.count))\n",
    "\n",
    "# Create DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'image_name': filenames,\n",
    "    'pred_label': predictions\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "output_csv = 'prediction.csv'\n",
    "results_df.to_csv(output_csv, index=False)\n",
    "print(f\"Predictions saved to {output_csv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PRDL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
